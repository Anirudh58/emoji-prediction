{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aedc5a19-7120-4590-b799-5906bfcd7f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import tqdm\n",
    "\n",
    "from collections import defaultdict\n",
    "import json\n",
    "import re\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sys.path.insert(0, '..')\n",
    "from src import emojilib\n",
    "\n",
    "# nlp\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import preprocessor as p\n",
    "import emoji"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd336163-9d0b-4d32-b4cb-541a72d714aa",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1d59b5-fe06-413a-84b3-55231c171f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = './'\n",
    "raw_tweets_file = 'tweet_by_ID_30_4_2022__08_11_07.txt'\n",
    "clean_data_folder_path = os.path.join(root_path, 'data', 'clean_data')\n",
    "raw_data_folder_path = os.path.join(root_path, 'data', 'raw_data')\n",
    "raw_tweets_path = os.path.join(raw_data_folder_path, raw_tweets_file)\n",
    "\n",
    "# target emojis\n",
    "mapping = { \n",
    "    'â¤':'0' , 'ğŸ˜':'1' , 'ğŸ˜‚':'2' , 'ğŸ’•':'3' , \n",
    "    'ğŸ”¥':'4' , 'ğŸ˜Š':'5' , 'ğŸ˜':'6' , 'âœ¨':'7' , \n",
    "    'ğŸ’™':'8' , 'ğŸ˜˜':'9' , 'ğŸ“·':'10' , 'ğŸ‡ºğŸ‡¸':'11' , \n",
    "    'â˜€':'12' , 'ğŸ’œ':'13' , 'ğŸ˜‰':'14' , 'ğŸ’¯':'15' , \n",
    "    'ğŸ˜':'16' , 'ğŸ„':'17' , 'ğŸ“¸':'18' , 'ğŸ˜œ':'19'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211b04ed-32c3-4b14-9168-3531a1451059",
   "metadata": {},
   "source": [
    "## Utility Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91d2ad7-ba6c-4ded-89bb-e6866f861e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_tweet(text):\n",
    "    \n",
    "    p.set_options(p.OPT.URL, p.OPT.MENTION, \n",
    "                  p.OPT.HASHTAG, p.OPT.RESERVED,\n",
    "                  p.OPT.NUMBER, p.OPT.SMILEY)\n",
    "    \n",
    "    cleaned_tweet = p.clean(text)\n",
    "    emoji_list = emojilib.emoji_list(cleaned_tweet)\n",
    "\n",
    "    return emoji_list, cleaned_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f447181f-d462-43db-b850-a8ece75aba8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_tweets(clean_data_folder_path, raw_tweets_file):\n",
    "    raw_tweets_file_name = raw_tweets_file.split('/')[-1]\n",
    "    out_text = open(os.path.join(clean_data_folder_path, raw_tweets_file_name + \".text\"), 'w')\n",
    "    out_labels = open(os.path.join(clean_data_folder_path, raw_tweets_file_name + \".labels\"), 'w')\n",
    "    out_ids = open(os.path.join(clean_data_folder_path, raw_tweets_file_name + \".ids\"), 'w')\n",
    "    \n",
    "    count = 0\n",
    "    with open(raw_tweets_file) as f_in:\n",
    "        for line in tqdm.tqdm(f_in):\n",
    "            json_data = json.loads(line)\n",
    "            tweet_id = json_data['id']\n",
    "            tweet_text = json_data['text'].replace(\"\\n\",\"\")\n",
    "            \n",
    "            emoji_list, cleaned_tweet = parse_tweet(tweet_text)\n",
    "            \n",
    "            # dump clean tweet\n",
    "            out_text.write(cleaned_tweet+\"\\n\")\n",
    "            \n",
    "            # dump the tweet id\n",
    "            out_ids.write(str(tweet_id)+\"\\n\")\n",
    "            \n",
    "            # dump the emoji data as space separated triplets (code, location, name)\n",
    "            for emoji in emoji_list:\n",
    "                location = emoji['location']\n",
    "                code = emoji['code']\n",
    "                name = emoji['name']\n",
    "                out_labels.write(f\"({mapping[code]},{location[0]},{name}) \")\n",
    "            out_labels.write(\"\\n\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf75979-85c1-412d-af88-42ee6cd51774",
   "metadata": {},
   "source": [
    "## Parse tweets (Run only once)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0eced5-988a-4bed-abaf-f0e12da54931",
   "metadata": {},
   "outputs": [],
   "source": [
    "#emoji_freq = parse_tweets(clean_data_folder_path, raw_tweets_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea06b98b-a31e-428e-98e2-9e827977cccc",
   "metadata": {},
   "source": [
    "## Visualize the distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d83cf8-ae38-4191-8edb-88a662a2c160",
   "metadata": {},
   "outputs": [],
   "source": [
    "emoji_freq = defaultdict(int)\n",
    "with open(os.path.join(clean_data_folder_path, 'tweet_by_ID_30_4_2022__08_11_07.txt.labels'), 'r') as f:\n",
    "    for line in f:\n",
    "        emojis = line.rstrip().split(' ')\n",
    "        #print(emojis)\n",
    "        if len(emojis) <= 1:\n",
    "            continue\n",
    "        for emoji in emojis:\n",
    "            emoji_code = int(emoji.split(',')[0][1:])\n",
    "            emoji_freq[emoji_code] += 1\n",
    "plt.bar(range(len(emoji_freq)), list(emoji_freq.values()), align='center')\n",
    "plt.xticks(range(len(emoji_freq)), list(emoji_freq.keys()))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321dadc2-29aa-4a36-853f-4b14f6edf742",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040c2fa6-2dab-4ba9-948c-c1326f393515",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e962a99-3067-4d95-8959-9346b4ef3743",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb036f4-9683-43a9-9392-b6a7e02b481a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "64fbc686-6a5c-428c-8665-3b6d4d224bfa",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_proj2",
   "language": "python",
   "name": "nlp_proj2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
