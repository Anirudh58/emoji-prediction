{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "2ec7c739-0a4a-4752-9580-9f4cd8c1df0a",
      "metadata": {
        "id": "2ec7c739-0a4a-4752-9580-9f4cd8c1df0a"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import os\n",
        "import random\n",
        "import re\n",
        "import sys\n",
        "import tqdm\n",
        "\n",
        "# data\n",
        "from collections import defaultdict\n",
        "from collections import Counter\n",
        "import numpy as np\n",
        "\n",
        "# viz\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# torch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "# pretrained embeddings\n",
        "import gensim.models as gsm"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2c5cf2d1-d906-47b6-99b1-1483acbbd0de",
      "metadata": {
        "id": "2c5cf2d1-d906-47b6-99b1-1483acbbd0de"
      },
      "source": [
        "## Config"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Pre-filtered GloVe embeddings\n",
        "!wget https://raw.githubusercontent.com/aritter/aritter.github.io/master/files/glove.840B.300d.conll_filtered.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8sEkIr30yfeH",
        "outputId": "a5af64e8-3930-4b19-f162-93c18a1f2b23"
      },
      "id": "8sEkIr30yfeH",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-05-03 02:40:05--  https://raw.githubusercontent.com/aritter/aritter.github.io/master/files/glove.840B.300d.conll_filtered.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 69798443 (67M) [text/plain]\n",
            "Saving to: ‘glove.840B.300d.conll_filtered.txt’\n",
            "\n",
            "glove.840B.300d.con 100%[===================>]  66.56M   241MB/s    in 0.3s    \n",
            "\n",
            "2022-05-03 02:40:07 (241 MB/s) - ‘glove.840B.300d.conll_filtered.txt’ saved [69798443/69798443]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "5bac0c4f-433f-45e7-b4f3-e88e476d10a9",
      "metadata": {
        "id": "5bac0c4f-433f-45e7-b4f3-e88e476d10a9"
      },
      "outputs": [],
      "source": [
        "root_path = '/content/'\n",
        "clean_data_folder_path = os.path.join(root_path, 'data', 'clean_data')\n",
        "glove_path = os.path.join(root_path, \"glove.840B.300d.conll_filtered.txt\")\n",
        "\n",
        "# target emojis\n",
        "mapping = { \n",
        "    '❤':'0' , '😍':'1' , '😂':'2' , '💕':'3' , \n",
        "    '🔥':'4' , '😊':'5' , '😎':'6' , '✨':'7' , \n",
        "    '💙':'8' , '😘':'9' , '📷':'10' , '🇺🇸':'11' , \n",
        "    '☀':'12' , '💜':'13' , '😉':'14' , '💯':'15' , \n",
        "    '😁':'16' , '🎄':'17' , '📸':'18' , '😜':'19'\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dff7809e-cd19-45e6-badf-5e8a5c9e5b23",
      "metadata": {
        "id": "dff7809e-cd19-45e6-badf-5e8a5c9e5b23"
      },
      "source": [
        "# Dataset Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "e5bccc57-9213-4fa0-9999-f92da3d4f7db",
      "metadata": {
        "id": "e5bccc57-9213-4fa0-9999-f92da3d4f7db"
      },
      "outputs": [],
      "source": [
        "class EmojiDataset(Dataset):\n",
        "    def __init__(self, dataset_path, transforms=None):\n",
        "        tweet_text_path = os.path.join(dataset_path, 'tweets.text')\n",
        "        tweet_label_path = os.path.join(dataset_path, 'tweets.labels')\n",
        "        tweet_tokenized_path = os.path.join(dataset_path, 'tweets.tokenized')\n",
        "        \n",
        "        # init glove\n",
        "        self.glove_emb = self.read_GloVe(glove_path)\n",
        "        \n",
        "        self.word_sentences = []\n",
        "        self.labels = []\n",
        "        \n",
        "        # curate the sentences\n",
        "        count = 0\n",
        "        for line in open(tweet_tokenized_path).readlines():\n",
        "            current_sentence = ['<START>']\n",
        "            current_sentence.extend(line.rstrip().split(' '))\n",
        "            current_sentence.append('<END>')\n",
        "            self.word_sentences.append(current_sentence)\n",
        "            \n",
        "            # count += 1\n",
        "            # if count > 50:\n",
        "            #     break\n",
        "                \n",
        "        # curate the labels\n",
        "        count = 0\n",
        "        for line in open(tweet_label_path).readlines():\n",
        "            emojis = line.rstrip().split(' ')\n",
        "            \n",
        "            try:\n",
        "                emoji_code = int(emojis[0].split(',')[0][1:])\n",
        "                self.labels.append(emoji_code)\n",
        "            except Exception as e:\n",
        "                # no emoji for this tweet\n",
        "                print(line)\n",
        "                self.labels.append(-1)\n",
        "            \n",
        "            # count += 1\n",
        "            # if count > 50:\n",
        "            #     break\n",
        "        \n",
        "        # compute char sentences from word sentences\n",
        "        self.char_sentences = self.sentences2char(self.word_sentences)\n",
        "        \n",
        "        # compute counts\n",
        "        self.word_counts = Counter([w for l in self.word_sentences for w in l])\n",
        "        self.char_counts = Counter([c for l in self.word_sentences for w in l for c in w])\n",
        "        self.singletons = set([w for (w,c) in self.word_counts.items() if c == 1 and not w in self.glove_emb.keys()])\n",
        "        self.char_singletons = set([w for (w,c) in self.char_counts.items() if c == 1])\n",
        "        \n",
        "        # Build dictionaries to map from words, characters to indices and vice versa.\n",
        "        # Save first two words in the vocabulary for padding and \"UNK\" token.\n",
        "        self.word2i = {w:i+2 for i,w in enumerate(set([w for l in self.word_sentences for w in l] + list(self.glove_emb.keys())))}\n",
        "        self.char2i = {w:i+2 for i,w in enumerate(set([c for l in self.char_sentences for w in l for c in w]))}\n",
        "        self.i2word = {i:w for w,i in self.word2i.items()}\n",
        "        self.i2char = {i:w for w,i in self.char2i.items()}\n",
        "        \n",
        "        # compute vocab size\n",
        "        self.vocab_size = max(self.word2i.values()) + 1\n",
        "        self.char_vocab_size = max(self.char2i.values()) + 1\n",
        "        \n",
        "        # emoji dictionaries.\n",
        "        self.emoji2i = {e:int(i) for e,i in mapping.items()}\n",
        "        self.i2emoji = {i:e for e,i in self.emoji2i.items()}\n",
        "    \n",
        "    def sentences2char(self, sentences):\n",
        "        return [[['start'] + [c for c in w] + ['end'] for w in l] for l in sentences]\n",
        "    \n",
        "    def read_GloVe(self, filename):\n",
        "        embeddings = {}\n",
        "        for line in open(filename).readlines():\n",
        "            #print(line)\n",
        "            fields = line.strip().split(\" \")\n",
        "            word = fields[0]\n",
        "            embeddings[word] = [float(x) for x in fields[1:]]\n",
        "        return embeddings\n",
        "    \n",
        "    #When training, randomly replace singletons with UNK tokens sometimes to simulate situation at test time.\n",
        "    def getDictionaryRandomUnk(self, w, dictionary, train=False):\n",
        "        if train and (w in self.singletons and random.random() > 0.5):\n",
        "            return 1\n",
        "        else:\n",
        "            return dictionary.get(w, 1)\n",
        "        \n",
        "    #Map a list of sentences from words to indices.\n",
        "    def sentences2indices(self, words, dictionary, train=False):\n",
        "        #1.0 => UNK\n",
        "        return [[self.getDictionaryRandomUnk(w,dictionary, train=train) for w in l] for l in words]\n",
        "    \n",
        "    #Map a list of sentences containing to indices (character indices)\n",
        "    def sentences2indicesChar(self, chars, dictionary):\n",
        "        #1.0 => UNK\n",
        "        return [[[dictionary.get(c,1) for c in w] for w in l] for l in chars]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bea3d2aa-06e8-4ae2-87ed-5e352a9c187d",
      "metadata": {
        "id": "bea3d2aa-06e8-4ae2-87ed-5e352a9c187d"
      },
      "source": [
        "## Test the dataset class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "512bbd36-210c-4bb0-a946-2fd9ccfaddd5",
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "512bbd36-210c-4bb0-a946-2fd9ccfaddd5",
        "outputId": "9e897167-8c76-4c3c-be61-35d3db8569c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "['<START>', 'So', 'lovely', 'catching', 'up', 'with', 'my', 'soul', 'sister', '<EMOJI>', 'University', 'of', 'Victoria', '<END>']\n",
            "[['start', '<', 'S', 'T', 'A', 'R', 'T', '>', 'end'], ['start', 'S', 'o', 'end'], ['start', 'l', 'o', 'v', 'e', 'l', 'y', 'end'], ['start', 'c', 'a', 't', 'c', 'h', 'i', 'n', 'g', 'end'], ['start', 'u', 'p', 'end'], ['start', 'w', 'i', 't', 'h', 'end'], ['start', 'm', 'y', 'end'], ['start', 's', 'o', 'u', 'l', 'end'], ['start', 's', 'i', 's', 't', 'e', 'r', 'end'], ['start', '<', 'E', 'M', 'O', 'J', 'I', '>', 'end'], ['start', 'U', 'n', 'i', 'v', 'e', 'r', 's', 'i', 't', 'y', 'end'], ['start', 'o', 'f', 'end'], ['start', 'V', 'i', 'c', 't', 'o', 'r', 'i', 'a', 'end'], ['start', '<', 'E', 'N', 'D', '>', 'end']]\n",
            "💜\n"
          ]
        }
      ],
      "source": [
        "dataset = EmojiDataset(clean_data_folder_path)\n",
        "\n",
        "test_idx = 5\n",
        "print(dataset.word_sentences[test_idx])\n",
        "print(dataset.char_sentences[test_idx])\n",
        "print(dataset.i2emoji[dataset.labels[test_idx]])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "035d0f5c-af7e-45c7-8d92-863f1fec2047",
      "metadata": {
        "id": "035d0f5c-af7e-45c7-8d92-863f1fec2047"
      },
      "source": [
        "## Utility Methods"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ba6ffd90-8129-4a7f-b81c-bba7c13b9295",
      "metadata": {
        "id": "ba6ffd90-8129-4a7f-b81c-bba7c13b9295"
      },
      "source": [
        "### Pad inputs to max sequence length (for batching)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "4fce133e-eb9a-4fc1-82ac-c4b32caac86a",
      "metadata": {
        "id": "4fce133e-eb9a-4fc1-82ac-c4b32caac86a"
      },
      "outputs": [],
      "source": [
        "def prepare_input(X_list):\n",
        "    X_padded = torch.nn.utils.rnn.pad_sequence([torch.as_tensor(l) for l in X_list], batch_first=True).type(torch.LongTensor) # padding the sequences with 0\n",
        "    X_mask   = torch.nn.utils.rnn.pad_sequence([torch.as_tensor([1.0] * len(l)) for l in X_list], batch_first=True).type(torch.FloatTensor) # consisting of 0 and 1, 0 for padded positions, 1 for non-padded positions\n",
        "    return (X_padded, X_mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "53e3ea32-84cb-4d0d-ba9c-a8a66051e0eb",
      "metadata": {
        "id": "53e3ea32-84cb-4d0d-ba9c-a8a66051e0eb"
      },
      "outputs": [],
      "source": [
        "#Maximum word length (for character representations)\n",
        "MAX_CLEN=32\n",
        "\n",
        "def prepare_input_char(X_list):\n",
        "    MAX_SLEN = max([len(l) for l in X_list])\n",
        "    X_padded  = [l + [[]]*(MAX_SLEN-len(l))  for l in X_list]\n",
        "    X_padded  = [[w[0:MAX_CLEN] for w in l] for l in X_padded]\n",
        "    X_padded  = [[w + [1]*(MAX_CLEN-len(w)) for w in l] for l in X_padded]\n",
        "    return torch.as_tensor(X_padded).type(torch.LongTensor)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d257e36f-528d-45a0-9446-150f43b3e1b9",
      "metadata": {
        "id": "d257e36f-528d-45a0-9446-150f43b3e1b9"
      },
      "source": [
        "### Pad outputs using one-hot encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "b76cad8d-8106-4ebf-887b-a83ef3e7b276",
      "metadata": {
        "id": "b76cad8d-8106-4ebf-887b-a83ef3e7b276"
      },
      "outputs": [],
      "source": [
        "def prepare_output_onehot(Y_list, NUM_TAGS=max(dataset.emoji2i.values())+1):\n",
        "    Y_onehot = [torch.zeros(len(l), NUM_TAGS) for l in Y_list]\n",
        "    for i in range(len(Y_list)):\n",
        "        for j in range(len(Y_list[i])):\n",
        "            Y_onehot[i][j,Y_list[i][j]] = 1.0\n",
        "    Y_padded = torch.nn.utils.rnn.pad_sequence(Y_onehot, batch_first=True).type(torch.FloatTensor)\n",
        "    return Y_padded"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Output Emojis to 300D vector using emoji2vec"
      ],
      "metadata": {
        "id": "0CpbEbK12e4A"
      },
      "id": "0CpbEbK12e4A"
    },
    {
      "cell_type": "code",
      "source": [
        "e2v_model = gsm.KeyedVectors.load_word2vec_format('/content/emoji2vec.txt', binary=False)"
      ],
      "metadata": {
        "id": "yso31D5t2eH4"
      },
      "id": "yso31D5t2eH4",
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#check\n",
        "happy_vector = e2v_model['❤'] \n",
        "print(happy_vector.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dXvpWg213Izz",
        "outputId": "efeec1e1-4b55-4b4c-be3c-e2c432b0d5e9"
      },
      "id": "dXvpWg213Izz",
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(300,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "emoji2vec_weights = torch.FloatTensor(e2v_model.wv.vectors)\n",
        "print(emoji2vec_weights.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AuwOaKNwGfoa",
        "outputId": "3288cc96-a8ea-4ac1-82fd-fcbac13d0909"
      },
      "id": "AuwOaKNwGfoa",
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1661, 300])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# labels - list of size N, each element is an emoji\n",
        "# return N x n_dim embeddings\n",
        "def prepare_output_vector(labels, n_dim=300):\n",
        "    N = len(labels)\n",
        "    Y_vector = torch.zeros((N, n_dim))\n",
        "    for i in range(0, N):\n",
        "        if labels[i][0] >= 0:\n",
        "          emoj = dataset.i2emoji[labels[i][0]]\n",
        "          #if emoj < 0 or emoj > 20:\n",
        "          #    print(i)\n",
        "          Y_vector[i, :] = torch.from_numpy(e2v_model[emoj])\n",
        "    return Y_vector\n",
        "\n",
        "inp_emoj_test = [ dataset.emoji2i['📸'], dataset.emoji2i['❤'], \n",
        "                             dataset.emoji2i['😂'], dataset.emoji2i['🔥'], dataset.emoji2i['😍']]\n",
        "inp_emoj_test = np.array(inp_emoj_test).reshape(-1, 1)\n",
        "print(inp_emoj_test)\n",
        "print(prepare_output_vector(inp_emoj_test).shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wSqbouDZ3bPH",
        "outputId": "12eae23b-79e1-45d7-8802-f91f2fb7768c"
      },
      "id": "wSqbouDZ3bPH",
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[18]\n",
            " [ 0]\n",
            " [ 2]\n",
            " [ 4]\n",
            " [ 1]]\n",
            "torch.Size([5, 300])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "qtrBIgUySK9Q"
      },
      "id": "qtrBIgUySK9Q",
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Word2Vec"
      ],
      "metadata": {
        "id": "ICZZ8n5H6ysn"
      },
      "id": "ICZZ8n5H6ysn"
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UsaNdx4S65Ni",
        "outputId": "171caca5-4554-491c-abab-fa6d4db0a3ed"
      },
      "id": "UsaNdx4S65Ni",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word2vec_model = gsm.KeyedVectors.load_word2vec_format('/content/drive/MyDrive/NLP/GoogleNews-vectors-negative300.bin.gz', binary=True)\n",
        "word2vec_weights = torch.FloatTensor(word2vec_model.wv.vectors)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IkZ5UrfZ60uP",
        "outputId": "413d9c75-3d45-4f94-9019-8991c1a93bd7"
      },
      "id": "IkZ5UrfZ60uP",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(word2vec_weights.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "55EOQrttcv2r",
        "outputId": "ec427ab3-c8fb-4fee-9be0-c7f2fffd0aff"
      },
      "id": "55EOQrttcv2r",
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3000000, 300])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example = word2vec_model.wv[\"california\"]\n",
        "print(example.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EL1OFFF260fH",
        "outputId": "10812c46-21a7-4f63-c25e-6a74c7a60e6f"
      },
      "id": "EL1OFFF260fH",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(300,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a227a28a-808b-4dfb-ac1e-d447546b857e",
      "metadata": {
        "id": "a227a28a-808b-4dfb-ac1e-d447546b857e"
      },
      "source": [
        "## Define training set and labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "bece1eb5-c477-4617-b75d-11c3487be717",
      "metadata": {
        "id": "bece1eb5-c477-4617-b75d-11c3487be717"
      },
      "outputs": [],
      "source": [
        "#Indices\n",
        "X       = dataset.sentences2indices(dataset.word_sentences, dataset.word2i, train=True)\n",
        "#X_char  = dataset.sentences2indicesChar(dataset.char_sentences, dataset.char2i)\n",
        "Y       = dataset.labels"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(dataset.word_sentences), len(Y))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aP_RLRIJYiNb",
        "outputId": "0f6be85d-8e7f-4aed-820b-2f19a1db30a4"
      },
      "id": "aP_RLRIJYiNb",
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "385351 385351\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "7d4c0547-e4a3-45b9-904d-4a005920921f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7d4c0547-e4a3-45b9-904d-4a005920921f",
        "outputId": "71652a05-c559-48c3-d835-1c10178ffe66"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max slen: 43\n"
          ]
        }
      ],
      "source": [
        "#print(\"max slen:\", max([len(x) for x in X_char]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "cc7f3317-a0ae-4463-8a05-5685b09a7697",
      "metadata": {
        "id": "cc7f3317-a0ae-4463-8a05-5685b09a7697"
      },
      "outputs": [],
      "source": [
        "(X_padded, X_mask) = prepare_input(X)\n",
        "#X_padded_char      = prepare_input_char(X_char)\n",
        "#Y_onehot           = prepare_output_onehot(Y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "4f1da96a-a6ff-43e6-8fd1-09f349a659fb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4f1da96a-a6ff-43e6-8fd1-09f349a659fb",
        "outputId": "74520948-376f-471a-b9b0-b844a63c4c82"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_padded: torch.Size([385351, 43])\n",
            "X_mask: torch.Size([385351, 43])\n",
            "Y shape: 385351\n"
          ]
        }
      ],
      "source": [
        "print(\"X_padded:\", X_padded.shape)\n",
        "print(\"X_mask:\", X_mask.shape)\n",
        "#print(\"X_padded_char:\", X_padded_char.shape)\n",
        "print(\"Y shape:\", len(Y))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y = np.array(Y).reshape(-1, 1)"
      ],
      "metadata": {
        "id": "lyNNMsW8XBR9"
      },
      "id": "lyNNMsW8XBR9",
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_padded[430], Y[430])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ErQkRsPf-sW0",
        "outputId": "c50e44d2-1c60-4dc7-c0fb-7431e10f5a15"
      },
      "id": "ErQkRsPf-sW0",
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 53855, 164628, 105972, 129111,  21328, 111177, 132491,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0]) 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train Test split"
      ],
      "metadata": {
        "id": "gXhjfSrFUVgO"
      },
      "id": "gXhjfSrFUVgO"
    },
    {
      "cell_type": "code",
      "source": [
        "N = len(Y)"
      ],
      "metadata": {
        "id": "Jw6wG0JIUqkN"
      },
      "id": "Jw6wG0JIUqkN",
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(1)\n",
        "ran = np.random.uniform(size=(N))"
      ],
      "metadata": {
        "id": "leqKV7ORUXfH"
      },
      "id": "leqKV7ORUXfH",
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fil = np.array(ran < 0.8, dtype=bool)\n",
        "word_sentences_train = [item for i, item in enumerate(dataset.word_sentences) if fil[i]]\n",
        "labels_train = [item for i, item in enumerate(dataset.labels) if fil[i]]\n",
        "ws_rem = [item for i, item in enumerate(dataset.word_sentences) if ~fil[i]]\n",
        "lab_rem = [item for i, item in enumerate(dataset.labels) if ~fil[i]]\n",
        "print(len(word_sentences_train), len(labels_train), len(ws_rem), len(lab_rem))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O31CxMVZUXVt",
        "outputId": "ce23830e-6b69-4ea9-b21f-b5fd570d313e"
      },
      "id": "O31CxMVZUXVt",
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "308396 308396 76955 76955\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rem = len(lab_rem)\n",
        "np.random.seed(2)\n",
        "ran = np.random.uniform(size=(rem))"
      ],
      "metadata": {
        "id": "7O0Weog9XH5z"
      },
      "id": "7O0Weog9XH5z",
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fil = np.array(ran < 0.5, dtype=bool)\n",
        "word_sentences_val = [item for i, item in enumerate(ws_rem) if fil[i]]\n",
        "labels_val = [item for i, item in enumerate(lab_rem) if fil[i]]\n",
        "word_sentences_test = [item for i, item in enumerate(ws_rem) if ~fil[i]]\n",
        "labels_test = [item for i, item in enumerate(lab_rem) if ~fil[i]]\n",
        "print(len(word_sentences_val), len(labels_val), len(word_sentences_test), len(labels_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kDQXNyguXP2x",
        "outputId": "f3b8310d-8348-4e09-c7fe-c23335fffd41"
      },
      "id": "kDQXNyguXP2x",
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "38544 38544 38411 38411\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7dbde428-e017-4cd0-9bf3-bae80ae3a57d",
      "metadata": {
        "id": "7dbde428-e017-4cd0-9bf3-bae80ae3a57d"
      },
      "source": [
        "# Start Modeling"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(torch.cuda.is_available())\n",
        "if torch.cuda.is_available():\n",
        "  device = torch.device(\"cuda\")\n",
        "else:\n",
        "  device = torch.device(\"cpu\")\n",
        "print(\"Using device:\", device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L3Qnm3N19hej",
        "outputId": "05120c42-5cec-4a0f-8b19-f45c5dfbc7af"
      },
      "id": "L3Qnm3N19hej",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n",
            "Using device: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "e2v_weights_mag = emoji2vec_weights.norm(dim=1)[:, None]\n",
        "e2v_weights_norm = emoji2vec_weights / torch.clamp(e2v_weights_mag, min=1e-8)\n",
        "print(e2v_weights_norm.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p4ZdAa1Rjyj6",
        "outputId": "8c178735-4d3a-4d2d-d2cb-377b54bd639f"
      },
      "id": "p4ZdAa1Rjyj6",
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1661, 300])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 140,
      "id": "8c9e5e07-134d-453a-981e-27e1d793fbb1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8c9e5e07-134d-453a-981e-27e1d793fbb1",
        "outputId": "c284fcb8-9f37-43fb-c648-d6a65e290b44"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lstm output shape: torch.Size([5, 300])\n",
            "Y onehot shape: torch.Size([5, 300])\n"
          ]
        }
      ],
      "source": [
        "class EmojiPredictor2(nn.Module):\n",
        "    def __init__(self, DIM_EMB=300, DIM_HID=500, DIM_OUTPUT=300):\n",
        "        super(EmojiPredictor2, self).__init__()\n",
        "\n",
        "        #self.emb = nn.Embedding(vocab_size, DIM_EMB)\n",
        "        self.emb = nn.Embedding.from_pretrained(word2vec_weights)\n",
        "        self.emb.requires_grad = False\n",
        "        #self.init_glove(GloVe)\n",
        "        self.rnn = nn.LSTM(DIM_EMB, DIM_HID, 1, bidirectional=True, batch_first=True)\n",
        "        \n",
        "        self.lin = nn.Linear(DIM_HID*2, DIM_OUTPUT)\n",
        "\n",
        "\n",
        "    def forward(self, X, train=False):\n",
        "        #print('X', X.shape)\n",
        "        embe = self.emb(X)\n",
        "        #print('embe', embe.shape)\n",
        "        op, (h_n, c_n) = self.rnn(embe)\n",
        "        #print('op', op.shape)\n",
        "        o = torch.max(op, dim=1).values\n",
        "        #print('o', o.shape)\n",
        "\n",
        "        out_vec = self.lin(o)\n",
        "        #print('out_vec', out_vec.shape)\n",
        "\n",
        "        return out_vec\n",
        "    '''\n",
        "    def init_glove(self, GloVe):\n",
        "        #TODO: initialize word embeddings using GloVe (you can skip this part in your first version, if you want, see instructions below).\n",
        "        #self.emb.weight.data.uniform_(-1, 1)\n",
        "        #self.emb = torch.nn.Embedding.from_pretrained(GloVe, freeze=False)\n",
        "        embeddings_matrix = np.zeros((vocab_size, self.DIM_EMB))\n",
        "\n",
        "        for i in i2word.keys():\n",
        "          try:\n",
        "            embeddings_matrix[i] = GloVe[i2word[i]]\n",
        "          except KeyError:\n",
        "            embeddings_matrix[i] = np.random.normal(scale=0.6, size=(self.DIM_EMB, ))\n",
        "\n",
        "        self.emb.load_state_dict({'weight': torch.from_numpy(embeddings_matrix)})\n",
        "        #pass\n",
        "    '''\n",
        "    def inference(self, sentences):\n",
        "        X = dataset.sentences2indices(sentences, dataset.word2i, train=False)\n",
        "        X = prepare_input(X)[0].to(device)\n",
        "        pred = self.forward(X)\n",
        "        pred_mag = pred.norm(dim=1)[:, None] \n",
        "        pred_norm = pred / torch.clamp(pred_mag, min=1e-8)\n",
        "        sim_mt = torch.mm(pred_norm, e2v_weights_norm.transpose(0, 1))\n",
        "        print(sim_mt.shape)\n",
        "        res = torch.argmax(sim_mt, dim=1)\n",
        "        print(res.shape)\n",
        "        #cosine similarity\n",
        "        return res\n",
        "        #return [dataset.i2emoji[i] for i in res]\n",
        "        #TO DO to map indices to emojis in emojitovec\n",
        "        #return [[i2tag[pred[i,j].item()] for j in range(len(sentences[i]))] for i in range(len(sentences))]\n",
        "\n",
        "    def print_predictions(self, words, tags):\n",
        "        Y_pred = self.inference(words)\n",
        "        print('Y_pred:', Y_pred)\n",
        "        print('Gold:', tags)\n",
        "        '''for i in range(len(words)):\n",
        "            print(\"----------------------------\")\n",
        "            print(\" \".join([f\"{words[i][j]}/{Y_pred[i][j]}/{tags[i][j]}\" for j in range(len(words[i]))]))\n",
        "            print(\"Predicted:\\t\", Y_pred[i])\n",
        "            print(\"Gold:\\t\\t\", tags[i])'''\n",
        "\n",
        "    def write_predictions(self, sentences, outFile):\n",
        "        fOut = open(outFile, 'w')\n",
        "        for s in sentences:\n",
        "            y = self.inference([s])[0]\n",
        "            #print(\"\\n\".join(y[1:len(y)-1]))\n",
        "            fOut.write(\"\\n\".join(y[1:len(y)-1]))  #Skip start and end tokens\n",
        "            fOut.write(\"\\n\\n\")\n",
        "\n",
        "#The following code will initialize a model and test that your forward computation runs without errors.\n",
        "lstm_test   = EmojiPredictor2(DIM_HID=500, DIM_EMB=300)\n",
        "lstm_output = lstm_test.forward(X_padded[11:16])\n",
        "Y_onehot    = prepare_output_vector(Y[11:16])\n",
        "\n",
        "#Check the shape of the lstm_output and one-hot label tensors.\n",
        "print(\"lstm output shape:\", lstm_output.shape)\n",
        "print(\"Y onehot shape:\", Y_onehot.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def shuffle_sentences(sentences, tags):\n",
        "    shuffled_sentences = []\n",
        "    shuffled_tags      = []\n",
        "    indices = list(range(len(sentences)))\n",
        "    random.shuffle(indices)\n",
        "    for i in indices:\n",
        "        shuffled_sentences.append(sentences[i])\n",
        "        shuffled_tags.append(tags[i])\n",
        "    return (shuffled_sentences, shuffled_tags)"
      ],
      "metadata": {
        "id": "HwCbQCFD9w4H"
      },
      "id": "HwCbQCFD9w4H",
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nEpochs = 5\n",
        "\n",
        "def train_emoji_predictor2(sentences, tags, lstm):\n",
        "  #optimizer = optim.Adadelta(lstm.parameters(), lr=0.0001)\n",
        "  #TODO: initialize optimizer\n",
        "    optimizer = torch.optim.Adadelta(lstm.parameters(), lr = 0.1)\n",
        "    batchSize = 5\n",
        "    tags = np.array(tags).reshape(-1, 1)\n",
        "    print(tags.shape)\n",
        "    #sentences = sentences[11:16] # TO DO remove\n",
        "    #tags = tags[11:16] # TO DO remove\n",
        "    #print(sentences, tags)\n",
        "\n",
        "    for epoch in range(nEpochs):\n",
        "        totalLoss = 0.0\n",
        "        lstm.train()\n",
        "        #(sentences_shuffled, tags_shuffled) = shuffle_sentences(sentences, tags) #TO DO remove\n",
        "        (sentences_shuffled, tags_shuffled) = (sentences, tags)\n",
        "        i = 0\n",
        "        sent = dataset.sentences2indices(sentences_shuffled, dataset.word2i, train=True)\n",
        "        #print(sent)\n",
        "        (sentences_input, sentence_mask) = prepare_input(sent)\n",
        "        #print(sentences_input)\n",
        "        \n",
        "        #print(\"sentences_input\", sentences_input.shape, sentences_input)\n",
        "        #gt_lab = sentences2indices(tags_shuffled, tag2i) #\n",
        "        #gt_lab = get_dummy_emoticons() #TO DO remove\n",
        "        #print(gt_lab)\n",
        "        gt_labels = prepare_output_vector(tags_shuffled)\n",
        "        #gt_labels = prepare_output_onehot(tags)\n",
        "        print(\"gt_labels\", gt_labels.shape) #, gt_labels\n",
        "        for batch in tqdm.notebook.tqdm(range(0, len(sentences), batchSize), leave=False):\n",
        "            lstm.zero_grad()\n",
        "            #TODO: Impelement gradient update.\n",
        "            optimizer.zero_grad()\n",
        "            #print(len(sentences_input))\n",
        "            #print(sentences_shuffled[i:max(i+batchSize, len(sentences))])\n",
        "            \n",
        "            input = sentences_input[i:min(i+batchSize, len(sentences))]\n",
        "            #print(input)\n",
        "            output = lstm.forward(input, train=True).to(device)\n",
        "            exp_output = gt_labels[i:min(i+batchSize, len(sentences))].to(device)\n",
        "            \n",
        "            #print(output.shape, exp_output.shape, torch.mul(output, exp_output).shape)\n",
        "            #print(\"out\", output, exp_output)\n",
        "\n",
        "            #mask = sentence_mask[i:min(i+batchSize, len(sentences))]\n",
        "            #prod = output.reshape(-1, output.shape[2]) * exp_output.reshape(-1, exp_output.shape[2])\n",
        "            \n",
        "            loss_fn = nn.MSELoss(reduction='sum')\n",
        "\n",
        "            loss = loss_fn(output, exp_output)\n",
        "            print('loss: ', loss)\n",
        "            #print(\"prod\", prod)\n",
        "            #loss = - torch.sum(prod) / torch.sum(exp_output)\n",
        "            \n",
        "            totalLoss += loss\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            i += batchSize\n",
        "            #if i >=50:\n",
        "            #  break\n",
        "        \n",
        "        lstm.eval()\n",
        "        print(f\"loss on epoch {epoch} = {totalLoss}\")\n",
        "        #lstm.write_predictions(sentences_dev, 'dev_pred')   #Performance on dev set\n",
        "        #lstm.write_predictions(sentences_dev, 'dev_pred')   #Performance on dev set\n",
        "        #print('conlleval:')\n",
        "        #print(subprocess.Popen('paste dev dev_pred | perl conlleval.pl -d \"\\t\"', shell=True, stdout=subprocess.PIPE,stderr=subprocess.STDOUT).communicate()[0].decode('UTF-8'))\n",
        "\n",
        "        if epoch % 5 == 0:\n",
        "            s = [1,2,3,4,5]#sample(range(len(word_sentences_val)), 5)\n",
        "            lstm.print_predictions([word_sentences_val[i] for i in s], [labels_val[i] for i in s])\n",
        "            #TO DO to map indices to emojis in emojitovec\n",
        "\n",
        "lstm = EmojiPredictor2(DIM_HID=500, DIM_EMB=300).to(device)\n",
        "train_emoji_predictor2(word_sentences_train, labels_train, lstm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226,
          "referenced_widgets": [
            "38c7fb83d83f427cb6681e6f980c1372",
            "7a241749928e403cbcc84fdb4d455127",
            "86e964837f134b98ae90322bc87b11d3",
            "e86670777f84479f9d9c00603ea29961",
            "f7ea5dc9a5d94322ba255e2ae8ea9399",
            "1b923f019a3242aba3c89916a92e09e7",
            "40857efa70f340febc4c48ea038b93e0",
            "4679b38b6579467891d523df4f6e737c",
            "d585dce10d5d4ca8a187db5298a26820",
            "c9654e4487de4f5ea5c1c3247f30c4f3",
            "38a00c2b04e94a38a21563cda65ed7f8"
          ]
        },
        "id": "KjuxB-WMAanH",
        "outputId": "a6d26d8c-5db4-4469-80df-fd09e2a3bf4d"
      },
      "id": "KjuxB-WMAanH",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(308396, 1)\n",
            "gt_labels torch.Size([308396, 300])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/61680 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "38c7fb83d83f427cb6681e6f980c1372"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss:  tensor(1925.7181, grad_fn=<MseLossBackward0>)\n",
            "loss:  tensor(2115.2371, grad_fn=<MseLossBackward0>)\n",
            "loss:  tensor(1926.1086, grad_fn=<MseLossBackward0>)\n",
            "loss:  tensor(2125.3462, grad_fn=<MseLossBackward0>)\n",
            "loss:  tensor(2396.4229, grad_fn=<MseLossBackward0>)\n",
            "loss:  tensor(2286.7473, grad_fn=<MseLossBackward0>)\n",
            "loss:  tensor(2435.9158, grad_fn=<MseLossBackward0>)\n",
            "loss:  tensor(1937.5304, grad_fn=<MseLossBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "jXDjQhOPDVC_"
      },
      "id": "jXDjQhOPDVC_",
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "7HWDJwu2gy4K"
      },
      "id": "7HWDJwu2gy4K",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "colab": {
      "name": "modeling.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "38c7fb83d83f427cb6681e6f980c1372": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7a241749928e403cbcc84fdb4d455127",
              "IPY_MODEL_86e964837f134b98ae90322bc87b11d3",
              "IPY_MODEL_e86670777f84479f9d9c00603ea29961"
            ],
            "layout": "IPY_MODEL_f7ea5dc9a5d94322ba255e2ae8ea9399"
          }
        },
        "7a241749928e403cbcc84fdb4d455127": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1b923f019a3242aba3c89916a92e09e7",
            "placeholder": "​",
            "style": "IPY_MODEL_40857efa70f340febc4c48ea038b93e0",
            "value": "  0%"
          }
        },
        "86e964837f134b98ae90322bc87b11d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4679b38b6579467891d523df4f6e737c",
            "max": 61680,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d585dce10d5d4ca8a187db5298a26820",
            "value": 8
          }
        },
        "e86670777f84479f9d9c00603ea29961": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c9654e4487de4f5ea5c1c3247f30c4f3",
            "placeholder": "​",
            "style": "IPY_MODEL_38a00c2b04e94a38a21563cda65ed7f8",
            "value": " 8/61680 [00:02&lt;6:05:54,  2.81it/s]"
          }
        },
        "f7ea5dc9a5d94322ba255e2ae8ea9399": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b923f019a3242aba3c89916a92e09e7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "40857efa70f340febc4c48ea038b93e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4679b38b6579467891d523df4f6e737c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d585dce10d5d4ca8a187db5298a26820": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c9654e4487de4f5ea5c1c3247f30c4f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "38a00c2b04e94a38a21563cda65ed7f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}